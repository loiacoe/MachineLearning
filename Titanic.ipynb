{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI5/3a8VUo08PGKzhDYJYs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhfxMSf-BcFK",
        "outputId": "be119d2e-c56f-4048-99bd-41d02fca69ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "iBSbqnUkBgEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "\n",
        "# Load and preprocess the Titanic dataset\n",
        "titanic_df = sns.load_dataset('titanic')\n",
        "\n",
        "# Drop non-numeric columns for simplicity\n",
        "titanic_df = titanic_df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Handle any NaN values by filling them with the mean of the column\n",
        "titanic_df = titanic_df.fillna(titanic_df.mean())\n",
        "\n",
        "# Separate the target variable (\"survived\") from the rest of the training data\n",
        "# Separate the target variable before scaling\n",
        "y = titanic_df[\"survived\"]\n",
        "X = titanic_df.drop(\"survived\", axis=1)\n",
        "\n",
        "\n",
        "# TODO: Use MinMaxScaler to scale the numeric features into a standard range\n",
        "# Hint: You will need to create an instance of MinMaxScaler, fit it on the data and transform the data\n",
        "scale = StandardScaler()\n",
        "X = pd.DataFrame(scale.fit_transform(X.values), columns=X.columns, index=X.index)\n",
        "\n",
        "# Recombine the scaled features with the original target variable\n",
        "scaled_titanic_df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Split the preprocessed dataset into the training and testing datasets with a 70%-30% split\n",
        "train_data, test_data = train_test_split(titanic_df, test_size=0.3, random_state=42)\n",
        "\n",
        "# Separate the target variable (\"survived\") from the rest of the training data\n",
        "x_train = train_data.drop(\"survived\", axis=1)\n",
        "y_train = train_data[\"survived\"]\n",
        "\n",
        "# Initialize a Logistic Regression model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Training the Logistic Regression model\n",
        "logreg.fit(x_train, y_train)\n",
        "\n",
        "# Separate the independent (x_test) and dependent (y_test) variables from the testing dataset\n",
        "x_test = test_data.drop(\"survived\", axis=1)\n",
        "y_test = test_data[\"survived\"]\n",
        "\n",
        "# Using the model to make predictions on the testing dataset\n",
        "predictions = logreg.predict(x_test)\n",
        "\n",
        "# Displaying metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "print(\"Accuracy Score:\")\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9wO4XqeBj3M",
        "outputId": "1e9e1d7f-c31b-463e-9dc6-313eb950acf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.91      0.80       157\n",
            "           1       0.79      0.47      0.59       111\n",
            "\n",
            "    accuracy                           0.73       268\n",
            "   macro avg       0.75      0.69      0.69       268\n",
            "weighted avg       0.74      0.73      0.71       268\n",
            "\n",
            "Accuracy Score:\n",
            "0.7276119402985075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TTJC5Cn-D4K-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}